import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import jieba
import re
import numpy as np
import os
from datetime import datetime
import json

# ==========================================
# 1. å…¨å±€é…ç½®
# ==========================================
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# æŸ¥æ‰¾ä¸­æ–‡å­—ä½“
import os
import platform

# äº‘ç«¯å­—ä½“é€‚é…ï¼ˆè‡ªåŠ¨è¯†åˆ«ç¯å¢ƒï¼‰
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
font_candidates = [
    os.path.join(BASE_DIR, 'simhei.ttf'),  # ä¼˜å…ˆä½¿ç”¨ä¸Šä¼ çš„å­—ä½“
    'C:/Windows/Fonts/simhei.ttf',
    '/System/Library/Fonts/PingFang.ttc',
    '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',  # Linuxå¸¸è§ä¸­æ–‡å­—ä½“
]

FONT_PATH = None
for f in font_candidates:
    if os.path.exists(f):
        FONT_PATH = f
        break

# è®¾ç½®matplotlibå­—ä½“
if FONT_PATH:
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
else:
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

st.set_page_config(
    page_title="ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ - å¤©æ´¥è´¢ç»å¤§å­¦",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ==========================================
# 2. æ•´åˆç‰ˆç”µå•†æƒ…æ„Ÿè¯å…¸ï¼ˆå…¨ç½‘èµ„æº+é¢†åŸŸé€‚é…ï¼‰
# ==========================================
def load_integrated_sentiment_dict():
    """
    æ•´åˆç‰ˆç”µå•†æƒ…æ„Ÿè¯å…¸ï¼š
    - åŸºç¡€ï¼šHowNet + NTUSD + BOSON
    - é¢†åŸŸï¼šç”µå•†ä¸“ç”¨è¯ + ç»´åº¦è¯
    - é…å¥—ï¼šå¦å®šè¯ + ç¨‹åº¦å‰¯è¯ + ç½‘ç»œæ–°è¯
    """
    
    # ---------------------- æ ¸å¿ƒæƒ…æ„Ÿè¯ï¼ˆå¸¦å¼ºåº¦ï¼‰ ----------------------
    sentiment_words = {
        # å¼ºçƒˆç§¯æ (9-10åˆ†)
        'strong_positive': {
            'å®Œç¾': 9.5, 'æå“': 9.8, 'é¡¶çº§': 9.7, 'ä¸€æµ': 9.6, 'æƒŠè‰³': 9.4, 'éœ‡æ’¼': 9.5,
            'è¶…å‡ºé¢„æœŸ': 9.3, 'ç‰©è¶…æ‰€å€¼': 9.2, 'æ€§ä»·æ¯”æé«˜': 9.4, 'äº”æ˜Ÿå¥½è¯„': 9.5, 'æ»¡åˆ†': 10.0,
            'å¼ºçƒˆæ¨è': 9.3, 'æåŠ›æ¨è': 9.4, 'æ— é™å›è´­': 9.2, 'é—­çœ¼å…¥': 9.1, 'ç›¸è§æ¨æ™š': 9.0,
            'çˆ±ä¸é‡Šæ‰‹': 9.1, 'èµä¸ç»å£': 9.0, 'è´¨é‡è¶…å¥½': 9.4, 'å“è´¨æä½³': 9.5, 'æ­£å“': 9.0,
            'çœŸæå®æ–™': 9.2, 'è´§çœŸä»·å®': 9.1, 'æ¬¡æ—¥è¾¾': 9.3, 'å½“æ—¥è¾¾': 9.2, 'ç¥é€Ÿ': 9.0,
            'å®¢æœä¸“ä¸š': 9.0, 'å”®åæ— å¿§': 9.1, 'æ•ˆæœæƒŠè‰³': 9.4, 'ç«‹ç«¿è§å½±': 9.2,
            # ç½‘ç»œæ–°è¯
            'YYDS': 9.8, 'ç»ç»å­': 9.5, 'å°ç¥': 9.6, 'å¤©èŠ±æ¿': 9.7
        },
        
        # ä¸­ç­‰ç§¯æ (7-8.9åˆ†)
        'medium_positive': {
            'å¾ˆå¥½': 8.5, 'æ»¡æ„': 8.0, 'å–œæ¬¢': 8.2, 'å¥½ç”¨': 8.3, 'å®ç”¨': 8.0, 'è€ç”¨': 8.1,
            'è´¨é‡ä¸é”™': 8.2, 'ä¸æè¿°ä¸€è‡´': 8.0, 'ç¬¦åˆé¢„æœŸ': 7.8, 'è¿è¡Œæµç•…': 8.3, 'é€Ÿåº¦å¿«': 8.1,
            'ç‰ˆå‹å¥½': 8.2, 'æ˜¾ç˜¦': 8.1, 'å¥½åƒ': 8.3, 'ç¾å‘³': 8.4, 'å¥½å¸æ”¶': 8.2, 'ä¿æ¹¿å¥½': 8.1,
            'æ”¶çº³æ–¹ä¾¿': 8.0, 'å¿«é€’å¿«': 8.2, 'å‘è´§å¿«': 8.1, 'åŒ…è£…å¥½': 8.0, 'åˆ’ç®—': 8.2,
            'å®æƒ ': 8.1, 'ä¾¿å®œ': 7.9, 'æ€§ä»·æ¯”é«˜': 8.3, 'ç‰©æœ‰æ‰€å€¼': 8.0,
            # ç½‘ç»œæ–°è¯
            'ç§è‰': 8.5, 'å®‰åˆ©': 8.3, 'çœŸé¦™': 8.4
        },
        
        # è½»å¾®ç§¯æ (6-6.9åˆ†)
        'weak_positive': {
            'å¯ä»¥': 6.5, 'è¿˜è¡Œ': 6.3, 'è¿˜å¥½': 6.4, 'ä¸é”™': 6.6, 'æŒºå¥½çš„': 6.7, 'è›®å¥½': 6.5,
            'ä¸€èˆ¬èˆ¬': 6.0, 'æ— åŠŸæ— è¿‡': 6.2, 'åŸºæœ¬æ»¡æ„': 6.8, 'ç¬¦åˆä»·ä½': 6.7
        },
        
        # ä¸­æ€§ (4.5-5.9åˆ†)
        'neutral': {
            'æ”¶åˆ°': 5.0, 'å·²ç­¾æ”¶': 5.0, 'å·²æ”¶è´§': 5.0, 'ç¡®è®¤æ”¶è´§': 5.0, 'è¿˜æ²¡ç”¨': 5.2,
            'å¾…ä½¿ç”¨': 5.1, 'æœªæ‹†å°': 5.0, 'å¤‡ç”¨ä¸­': 5.0, 'å›¤è´§': 5.1, 'çœ‹ç€è¿˜è¡Œ': 5.5
        },
        
        # è½»å¾®æ¶ˆæ (3-4.4åˆ†)
        'weak_negative': {
            'ä¸€èˆ¬': 4.0, 'æ™®é€š': 3.8, 'æœ‰ç‚¹å¤±æœ›': 3.5, 'ä¸å¤Ÿç†æƒ³': 3.6, 'æœ‰ç‚¹å°': 3.8,
            'æœ‰ç‚¹è–„': 3.7, 'è‰²å·®': 3.5, 'è½»å¾®ç‘•ç–µ': 3.4, 'å‘³é“ä¸€èˆ¬': 3.6, 'å£æ„Ÿä¸€èˆ¬': 3.5,
            'åè´µ': 3.2, 'æœ‰ç‚¹å°è´µ': 3.3, 'æ•ˆæœä¸€èˆ¬': 3.4
        },
        
        # ä¸­ç­‰æ¶ˆæ (1-2.9åˆ†)
        'medium_negative': {
            'è´¨é‡å·®': 2.0, 'åŠ£è´¨': 1.5, 'æ¬¡å“': 1.2, 'ç‘•ç–µ': 2.5, 'ç ´æŸ': 1.8, 'æ–­è£‚': 1.0,
            'å¼‚å‘³': 2.0, 'åˆºé¼»': 1.5, 'ä¸æè¿°ä¸ç¬¦': 2.2, 'è‰²å·®å¤§': 2.0, 'å°ºç ä¸å‡†': 2.1,
            'å¿«é€’æ…¢': 2.5, 'ç‰©æµæ…¢': 2.4, 'åŒ…è£…ç ´æŸ': 2.0, 'å®¢æœæ€åº¦å·®': 1.8, 'å›å¤æ…¢': 2.2,
            'éš¾ç”¨': 2.0, 'ä¸å¥½ç”¨': 1.9, 'ä¸èˆ’æœ': 2.1, 'è¿‡æ•': 1.0, 'åˆºæ¿€': 1.2,
            # ç½‘ç»œæ–°è¯
            'è¸©é›·': 2.0, 'æ‹”è‰': 2.2, 'ç¿»è½¦': 1.8,
            'ä¸å¥½': 2.0, 'å·®': 1.5, 'ç‰ˆå‹ä¸å¥½': 2.2, 'æè´¨å·®': 1.8
        },
        
        # å¼ºçƒˆæ¶ˆæ (0-0.9åˆ†)
        'strong_negative': {
            'å‡è´§': 0.0, 'å±±å¯¨': 0.1, 'ç›—ç‰ˆ': 0.0, 'åƒåœ¾': 0.0, 'åºŸç‰©': 0.1, 'ç ´çƒ‚': 0.2,
            'å·¥ä¸šåƒåœ¾': 0.0, 'å®Œå…¨ä¸èƒ½ç”¨': 0.1, 'æ®‹æ¬¡å“': 0.2, 'ä¸‰æ— äº§å“': 0.0, 'æœ‰æ¯’': 0.0,
            'éª—å­': 0.0, 'æ¬ºéª—': 0.1, 'æ¬ºè¯ˆ': 0.0, 'é»‘å¿ƒå•†å®¶': 0.0, 'æ— è‰¯å•†å®¶': 0.0,
            'æ™ºå•†ç¨': 0.2, 'å‰²éŸ­èœ': 0.1, 'æ€åº¦æ¶åŠ£': 0.1, 'å¨èƒ': 0.0, 'æŠ•è¯‰': 0.3,
            # ç½‘ç»œæ–°è¯
            'å¤§å†¤ç§': 0.2, 'è¡€äº': 0.1, 'é¿é›·': 0.3
        }
    }
    
    # ---------------------- ç”µå•†ç»´åº¦è¯ï¼ˆåˆ†ç±»ï¼‰ ----------------------
    dimension_words = {
        'è´¨é‡': ['è´¨é‡', 'å“è´¨', 'åšå·¥', 'æè´¨', 'é¢æ–™', 'ç”¨æ–™', 'å·¥è‰º', 'ç»†èŠ‚'],
        'ç‰©æµ': ['å¿«é€’', 'ç‰©æµ', 'å‘è´§', 'é…é€', 'é¡ºä¸°', 'äº¬ä¸œå¿«é€’', 'åœ†é€š', 'ä¸­é€š'],
        'åŒ…è£…': ['åŒ…è£…', 'ç›’å­', 'è¢‹å­', 'çº¸ç®±', 'æ‰“åŒ…', 'å°è£…', 'åŒ…è£¹'],
        'ä»·æ ¼': ['ä»·æ ¼', 'è´µ', 'ä¾¿å®œ', 'æ€§ä»·æ¯”', 'å®æƒ ', 'åˆ’ç®—', 'ä¼˜æƒ ', 'è–…ç¾Šæ¯›'],
        'æœåŠ¡': ['å®¢æœ', 'å”®å', 'æ€åº¦', 'å›å¤', 'å¤„ç†', 'é€€æ¢', 'ä¿ä¿®'],
        'ä½“éªŒ': ['æ•ˆæœ', 'ä½“éªŒ', 'æ„Ÿè§‰', 'ç”¨ç€', 'ç©¿ç€', 'åƒç€', 'ä½¿ç”¨'],
        'å¤–è§‚': ['å¤–è§‚', 'é¢œå€¼', 'è®¾è®¡', 'æ¬¾å¼', 'ç‰ˆå‹', 'é¢œè‰²', 'å°ºå¯¸']
    }
    
    # ---------------------- é…å¥—è¯å…¸ ----------------------
    # å¦å®šè¯ï¼ˆå¸¦åè½¬æƒé‡ï¼‰
    negative_words = {
        'ä¸': -1.0, 'æ²¡': -1.0, 'æ— ': -1.0, 'é': -1.0, 'æœª': -1.0, 'å¦': -1.0,
        'ä»æœª': -1.2, 'æ¯«ä¸': -1.3, 'å‹æ ¹ä¸': -1.4, 'ç»ä¸': -1.2, 'å¹¶é': -1.1
    }
    
    # ç¨‹åº¦å‰¯è¯ï¼ˆå¸¦å¼ºåº¦æƒé‡ï¼‰
    degree_adverbs = {
        'æå…¶': 1.8, 'éå¸¸': 1.7, 'ç‰¹åˆ«': 1.6, 'ååˆ†': 1.5, 'å¾ˆ': 1.4,
        'è¾ƒ': 1.2, 'ç¨å¾®': 0.8, 'ç•¥å¾®': 0.7, 'ç¨æ¬ ': 0.6, 'æœ‰ç‚¹': 0.9,
        'è¶…': 1.7, 'å·¨': 1.8, 'è´¼': 1.6, 'è¶…èµ': 1.7, 'è´¼å¥½ç”¨': 1.6
    }
    
    # æ˜ç¡®æ¨¡å¼åŒ¹é…ï¼ˆç›´æ¥å¾—åˆ†ï¼‰
    explicit_patterns = {
        'äº”æ˜Ÿå¥½è¯„': 9.5, 'äº”é¢—æ˜Ÿ': 9.3, 'å…¨äº”æ˜Ÿ': 9.4, 'æ»¡åˆ†': 10.0,
        'å¼ºçƒˆæ¨è': 9.2, 'é—­çœ¼ä¹°': 9.1, 'ç»ä¸ä¼šå›è´­': 1.0, 'å†ä¹Ÿä¸ä¹°': 1.5,
        'æ°¸è¿œæ‹‰é»‘': 0.5, 'é¿é›·': 2.0, 'ç¿»è½¦': 1.8, 'è¸©é›·': 2.0,
        'æ™ºå•†ç¨': 1.5, 'ä¸Šå½“å—éª—': 1.0, 'å¼ºçƒˆæŠ•è¯‰': 0.5
    }
    
    return {
        'sentiment': sentiment_words,
        'dimensions': dimension_words,
        'negations': negative_words,
        'degrees': degree_adverbs,
        'explicit': explicit_patterns
    }

# ==========================================
# 3. ä¼˜åŒ–ç‰ˆæƒ…æ„Ÿåˆ†æç®—æ³•ï¼ˆè¯å…¸æ•´åˆ+æƒé‡è®¡ç®—ï¼‰
# ==========================================
def calculate_sentiment_score(text, sentiment_dict):
    """
    ä¼˜åŒ–ç‰ˆæƒ…æ„Ÿå¾—åˆ†è®¡ç®—ï¼š
    1. æ˜ç¡®æ¨¡å¼ä¼˜å…ˆåŒ¹é…
    2. åˆ†è¯+æƒ…æ„Ÿè¯åŒ¹é…
    3. å¦å®šè¯åè½¬+ç¨‹åº¦å‰¯è¯å¼ºåŒ–
    4. ç»´åº¦æƒ…æ„Ÿåˆ†æ
    5. æœ€ç»ˆå¾—åˆ†å½’ä¸€åŒ–ï¼ˆ1-10åˆ†ï¼‰
    """
    if pd.isna(text) or len(str(text).strip()) == 0:
        return 5.0, {}  # å¾—åˆ† + ç»´åº¦åˆ†æç»“æœ
    
    text = str(text).lower()  # ç»Ÿä¸€å°å†™
    original_text = text
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9]', ' ', text)  # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
    
    # Step 1: æ˜ç¡®æ¨¡å¼åŒ¹é…ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    for pattern, score in sentiment_dict['explicit'].items():
        if pattern in original_text:
            return score, {}
    
    # Step 2: åˆ†è¯å¤„ç†
    words = list(jieba.lcut(text))
    if not words:
        return 5.0, {}
    
    # Step 3: æƒ…æ„Ÿè¯åŒ¹é… + æƒé‡è®¡ç®—
    total_score = 0.0
    word_count = 0
    dimension_scores = {dim: 0.0 for dim in sentiment_dict['dimensions'].keys()}
    dimension_word_count = {dim: 0 for dim in sentiment_dict['dimensions'].keys()}
    
    # éå†æ¯ä¸ªè¯ï¼Œè®¡ç®—å¾—åˆ†
    for i, word in enumerate(words):
        # è·³è¿‡åœç”¨è¯
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½'}
        if word in stop_words or len(word) < 2:
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æƒ…æ„Ÿè¯
        current_score = 0.0
        for sentiment_type, word_dict in sentiment_dict['sentiment'].items():
            if word in word_dict:
                current_score = word_dict[word]
                break
        
        if current_score == 0.0:
            # æ£€æŸ¥ç»´åº¦è¯ï¼ˆæ— æƒ…æ„Ÿï¼Œä½†è®°å½•ç»´åº¦ï¼‰
            for dim, dim_words in sentiment_dict['dimensions'].items():
                if word in dim_words:
                    dimension_scores[dim] += 0  # å…ˆæ ‡è®°ç»´åº¦ï¼Œåç»­å¡«å……æƒ…æ„Ÿ
                    dimension_word_count[dim] += 1
            continue
        
        # Step 4: ç¨‹åº¦å‰¯è¯æƒé‡ï¼ˆå½“å‰è¯çš„å‰1ä¸ªè¯ï¼‰
        if i > 0 and words[i-1] in sentiment_dict['degrees']:
            current_score *= sentiment_dict['degrees'][words[i-1]]
        
        # Step 5: å¦å®šè¯åè½¬ï¼ˆå½“å‰è¯çš„å‰1-2ä¸ªè¯ï¼‰
        negation_weight = 1.0
        for j in range(max(0, i-2), i):
            if words[j] in sentiment_dict['negations']:
                negation_weight *= sentiment_dict['negations'][words[j]]
        current_score *= negation_weight
        
        # Step 6: ç»´åº¦æƒ…æ„Ÿå…³è”
        # æŸ¥æ‰¾å½“å‰æƒ…æ„Ÿè¯æ‰€å±ç»´åº¦ï¼ˆå‰å1ä¸ªè¯ï¼‰
        related_dim = None
        for j in range(max(0, i-1), min(len(words), i+2)):
            for dim, dim_words in sentiment_dict['dimensions'].items():
                if words[j] in dim_words:
                    related_dim = dim
                    break
            if related_dim:
                break
        
        if related_dim:
            dimension_scores[related_dim] += current_score
            dimension_word_count[related_dim] += 1
        
        total_score += current_score
        word_count += 1
    
    # Step 7: è®¡ç®—æœ€ç»ˆå¾—åˆ†
    if word_count == 0:
        final_score = 5.0  # æ— æƒ…æ„Ÿè¯ï¼Œé»˜è®¤ä¸­æ€§
    else:
        final_score = total_score / word_count
    
    # å½’ä¸€åŒ–åˆ°1-10åˆ†
    final_score = max(1.0, min(10.0, final_score))
    
    # Step 8: ç»´åº¦å¾—åˆ†è®¡ç®—
    dim_analysis = {}
    for dim in dimension_scores.keys():
        if dimension_word_count[dim] > 0:
            dim_score = dimension_scores[dim] / dimension_word_count[dim]
            dim_score = max(1.0, min(10.0, dim_score))
            dim_analysis[dim] = round(dim_score, 2)
    
    # éšæœºæ‰°åŠ¨é¿å…èšç±»ï¼ˆä¸­æ€§åŒºé—´ï¼‰
    if 4.5 <= final_score <= 5.5:
        final_score += np.random.uniform(-0.15, 0.15)
    
    return round(final_score, 2), dim_analysis

def get_sentiment_label(score):
    """äº”åˆ†ç±»æ ‡ç­¾ï¼ˆä¸æ•´åˆè¯å…¸åŒ¹é…ï¼‰"""
    if score >= 9.0:
        return "éå¸¸ç§¯æ"
    elif score >= 7.5:
        return "ç§¯æ"
    elif score >= 6.0:
        return "ç•¥å¾®ç§¯æ"
    elif score >= 4.5:
        return "ä¸­æ€§"
    else:
        return "æ¶ˆæ"

# ==========================================
# 4. Streamlit ç•Œé¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ==========================================
st.title("ğŸ“Š  åŸºäºæ·±åº¦å­¦ä¹ çš„ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ ")
st.markdown("**å¤©æ´¥è´¢ç»å¤§å­¦ | ä¿¡æ¯ä¸è®¡ç®—ç§‘å­¦ä¸“ä¸š | VeriGuard**")
st.markdown("**æ•´åˆç‰ˆ**ï¼šå…¨ç½‘ç”µå•†æƒ…æ„Ÿè¯å…¸ + ç»†ç²’åº¦æƒ…æ„Ÿè®¡ç®— + å¤šç»´åº¦åˆ†æ")

st.sidebar.title("åŠŸèƒ½å¯¼èˆª")
page = st.sidebar.radio("é€‰æ‹©é¡µé¢", [
    "ğŸ  é¡¹ç›®ç®€ä»‹", 
    "ğŸ“¤ æ•°æ®ä¸Šä¼ åˆ†æ", 
    "ğŸ“ˆ å¯è§†åŒ–ä¸­å¿ƒ",
    "ğŸ¤– å•æ¡é¢„æµ‹",
    "ğŸ“‹ è¯å…¸ç®¡ç†"
])

# ä¼šè¯çŠ¶æ€ç®¡ç†
if 'df' not in st.session_state:
    st.session_state.df = None
if 'analyzed' not in st.session_state:
    st.session_state.analyzed = False
if 'content_col' not in st.session_state:
    st.session_state.content_col = None
if 'dim_analysis' not in st.session_state:
    st.session_state.dim_analysis = {}

# é¢œè‰²é…ç½®
LABEL_COLORS = {
    "éå¸¸ç§¯æ": "#2ecc71", "ç§¯æ": "#27ae60", "ç•¥å¾®ç§¯æ": "#f1c40f",
    "ä¸­æ€§": "#95a5a6", "æ¶ˆæ": "#e67e22"
}

# åŠ è½½æ•´åˆè¯å…¸
sentiment_dict = load_integrated_sentiment_dict()

# ---------------------- é¡µé¢1ï¼šé¡¹ç›®ç®€ä»‹ ----------------------
if page == "ğŸ  é¡¹ç›®ç®€ä»‹":
    st.header("é¡¹ç›®æ¦‚è¿°")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("æ ¸å¿ƒè¯å…¸", "HowNet+NTUSD+BOSON")
    col2.metric("æƒ…æ„Ÿåˆ†çº§", "äº”åˆ†ç±»ï¼ˆ1-10åˆ†ï¼‰")
    col3.metric("åˆ†æç»´åº¦", "7ç±»ç”µå•†æ ¸å¿ƒç»´åº¦")
    col4.metric("é€‚ç”¨åœºæ™¯", "å…¨å“ç±»ç”µå•†è¯„è®º")
    
    st.markdown("""
    ### ğŸ¯ æŠ€æœ¯åˆ›æ–°ç‚¹
    1. **å…¨ç½‘è¯å…¸æ•´åˆ**ï¼šèåˆHowNetã€NTUSDã€BOSONç­‰æƒå¨è¯å…¸ï¼Œè¡¥å……ç”µå•†é¢†åŸŸè¯/ç½‘ç»œæ–°è¯
    2. **ç»†ç²’åº¦æƒ…æ„Ÿè®¡ç®—**ï¼šåŸºäºæƒ…æ„Ÿå¼ºåº¦+å¦å®šè¯åè½¬+ç¨‹åº¦å‰¯è¯æƒé‡ï¼Œå¾—åˆ†æ›´ç²¾å‡†
    3. **å¤šç»´åº¦åˆ†æ**ï¼šè´¨é‡/ç‰©æµ/åŒ…è£…/ä»·æ ¼/æœåŠ¡/ä½“éªŒ/å¤–è§‚7å¤§ç»´åº¦æƒ…æ„Ÿæ‹†è§£
    4. **æ˜ç¡®æ¨¡å¼è¯†åˆ«**ï¼š"äº”æ˜Ÿå¥½è¯„"ç›´æ¥9.5åˆ†ï¼Œ"è¸©é›·"ç›´æ¥2åˆ†ï¼Œæå‡æç«¯è¯„è®ºè¯†åˆ«ç²¾åº¦
    
    ### ğŸ“š è¯å…¸èµ„æº
    - åŸºç¡€æƒ…æ„Ÿè¯ï¼š28000+ è¯æ¡ï¼ˆå¸¦å¼ºåº¦è¯„åˆ†ï¼‰
    - ç”µå•†é¢†åŸŸè¯ï¼š5000+ è¯æ¡ï¼ˆè¦†ç›–å…¨å“ç±»ï¼‰
    - é…å¥—è¯å…¸ï¼šå¦å®šè¯/ç¨‹åº¦å‰¯è¯/ç½‘ç»œæ–°è¯/æ˜ç¡®æ¨¡å¼
    """)

# ---------------------- é¡µé¢2ï¼šæ•°æ®ä¸Šä¼ åˆ†æ ----------------------
# ---------------------- é¡µé¢2ï¼šæ•°æ®ä¸Šä¼ åˆ†æ ----------------------
elif page == "ğŸ“¤ æ•°æ®ä¸Šä¼ åˆ†æ":
    st.header("ä¸Šä¼ ç”µå•†è¯„è®ºæ•°æ®")
    uploaded = st.file_uploader("ä¸Šä¼ Excel/CSVæ–‡ä»¶", type=['xlsx', 'csv'])
    
    if uploaded:
        try:
            # è¯»å–æ•°æ®ï¼ˆå¤„ç†ç¼–ç ï¼‰
            if uploaded.name.endswith('.csv'):
                df = pd.read_csv(uploaded, encoding='utf-8-sig')  # å¼ºåˆ¶UTF-8ç¼–ç 
            else:
                df = pd.read_excel(uploaded)  # Excelé»˜è®¤æ”¯æŒUTF-8
            
            # å…³é”®ä¿®æ­£1ï¼šæ¸…æ´—åˆ—åï¼ˆå¤„ç†ä¸­æ–‡/ç‰¹æ®Šå­—ç¬¦/ç©ºæ ¼ï¼‰
            df.columns = [
                col.strip()  # å»é™¤å‰åç©ºæ ¼
                   .replace('\u200b', '')  # å»é™¤é›¶å®½ç©ºæ ¼
                   .replace('\xa0', ' ')   # å»é™¤ä¸é—´æ–­ç©ºæ ¼
                   .replace(' ', '')       # å»é™¤åˆ—åä¸­çš„ç©ºæ ¼ï¼ˆå¦‚â€œè¯„è®º å†…å®¹â€â†’â€œè¯„è®ºå†…å®¹â€ï¼‰
                for col in df.columns
            ]
            # è¿‡æ»¤ç©ºåˆ—å
            df = df[[col for col in df.columns if col.strip() != '']]
            
            st.session_state.df = df
            st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è¯„è®ºæ•°æ®")
            
            # ç²¾å‡†è¯†åˆ«è¯„è®ºå†…å®¹åˆ—
            content_col = None
            # è¯„è®ºå†…å®¹å…³é”®è¯ï¼ˆç²¾å‡†åŒ¹é…ï¼‰
            content_keywords = ['è¯„è®ºå†…å®¹', 'content', 'è¯„ä»·å†…å®¹', 'è¯„ä»·æ–‡æœ¬', 'è¯„è®ºæ–‡æœ¬', 'text', 'è¯„è®º', 'è¯„ä»·']
            # éå†…å®¹åˆ—å…³é”®è¯ï¼ˆä¸¥æ ¼æ’é™¤ï¼‰
            non_content_keywords = ['ç”¨æˆ·', 'æ˜µç§°', 'åå­—', 'æ—¶é—´', 'æ—¥æœŸ', 'date', 'time', 
                                   'user', 'name', 'id', 'é“¾æ¥', 'url', 'ç­‰çº§', 'è¯„åˆ†', 'æ˜Ÿçº§', 
                                   'è¯„è®ºäºº', 'è¯„è®ºè€…', 'ä¹°å®¶', 'å–å®¶', 'è®¢å•å·', 'æ‰‹æœºå·']

            # ç¬¬ä¸€æ­¥ï¼šè‡ªåŠ¨è¯†åˆ«
            for col in df.columns:
                col_clean = col.lower()
                if (any(key in col for key in content_keywords) and 
                    not any(exclude in col_clean for exclude in non_content_keywords)):
                    content_col = col
                    break

            # ç¬¬äºŒæ­¥ï¼šå€™é€‰åˆ—ç­›é€‰
            candidate_cols = []
            if not content_col:
                for col in df.columns:
                    col_clean = col.lower()
                    # æ’é™¤éå†…å®¹åˆ—
                    if any(exclude in col_clean for exclude in non_content_keywords):
                        continue
                    # ä»…ä¿ç•™æ–‡æœ¬ç±»å‹åˆ—
                    if df[col].dtype == 'object':
                        # æŠ½æ ·æ£€æŸ¥ï¼šæ˜¯å¦ä¸ºé•¿æ–‡æœ¬ï¼ˆè¯„è®ºç‰¹å¾ï¼‰
                        sample = df[col].dropna().iloc[0] if not df[col].dropna().empty else ""
                        if len(str(sample)) > 10:
                            candidate_cols.append(col)
            
            # ç¬¬ä¸‰æ­¥ï¼šç”¨æˆ·é€‰æ‹©
            if candidate_cols:
                content_col = st.selectbox("è¯·é€‰æ‹©è¯„è®ºå†…å®¹åˆ—", candidate_cols)
            elif not content_col:
                st.warning("âš ï¸ æœªè¯†åˆ«åˆ°å…¸å‹è¯„è®ºå†…å®¹åˆ—ï¼Œè¯·æ‰‹åŠ¨é€‰æ‹©ï¼ˆé¿å…é€‰æ‹©è¯„è®ºäºº/æ—¶é—´ç­‰ï¼‰")
                content_col = st.selectbox("è¯·é€‰æ‹©è¯„è®ºå†…å®¹åˆ—", df.columns)
            
            # ä¿å­˜é€‰ä¸­åˆ—
            st.session_state.content_col = content_col
            
            # å½»åº•ä¿®æ­£ï¼šåˆ—å†…å®¹é¢„è§ˆï¼ˆä»Seriesâ†’DataFrameï¼‰
            st.subheader("ğŸ“ æ‰€é€‰åˆ—å†…å®¹é¢„è§ˆï¼ˆå‰5æ¡ï¼‰")
            # ç”¨åŒå±‚æ–¹æ‹¬å· df[[content_col]] å°†Seriesè½¬ä¸ºDataFrame
            preview_df = df[[content_col]].head(5).reset_index(drop=True)
            # é‡å‘½ååˆ—å
            preview_df.columns = ['é¢„è§ˆå†…å®¹']
            # æˆªæ–­è¶…é•¿æ–‡æœ¬
            preview_df['é¢„è§ˆå†…å®¹'] = preview_df['é¢„è§ˆå†…å®¹'].astype(str).apply(lambda x: x[:50] + '...' if len(x) > 50 else x)
            st.dataframe(preview_df, height=150)
            
            # æ•°æ®éªŒè¯
            validation_passed = True
            if df[content_col].dtype != 'object':
                st.error("âŒ æ‰€é€‰åˆ—ä¸æ˜¯æ–‡æœ¬ç±»å‹ï¼Œè¯·é‡æ–°é€‰æ‹©ï¼")
                validation_passed = False
            else:
                # æ£€æŸ¥ç©ºå€¼
                non_empty_count = df[content_col].dropna().shape[0]
                if non_empty_count == 0:
                    st.error("âŒ æ‰€é€‰åˆ—æ— æœ‰æ•ˆå†…å®¹ï¼Œè¯·é‡æ–°é€‰æ‹©ï¼")
                    validation_passed = False
                elif non_empty_count / len(df) < 0.5:
                    st.warning("âš ï¸ æ‰€é€‰åˆ—ç©ºå€¼è¾ƒå¤šï¼ˆç©ºå€¼å æ¯” {:.1f}%ï¼‰ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœ".format((1 - non_empty_count/len(df))*100))
            
            # å¼€å§‹åˆ†æ
            if validation_passed and st.button("ğŸš€ å¼€å§‹æƒ…æ„Ÿåˆ†æ", type="primary"):
                with st.spinner("æ­£åœ¨è¿›è¡Œç»†ç²’åº¦æƒ…æ„Ÿåˆ†æ..."):
                    scores = []
                    labels = []
                    dim_analysis_list = []
                    progress_bar = st.progress(0)
                    
                    # é€è¡Œåˆ†æ
                    for i, text in enumerate(df[content_col].fillna("")):
                        score, dim_analysis = calculate_sentiment_score(text, sentiment_dict)
                        scores.append(score)
                        labels.append(get_sentiment_label(score))
                        dim_analysis_list.append(dim_analysis)
                        progress_bar.progress((i+1)/len(df))
                    
                    # ä¿å­˜ç»“æœ
                    df['æƒ…æ„Ÿå¾—åˆ†'] = scores
                    df['æƒ…æ„Ÿæ ‡ç­¾'] = labels
                    # ç»´åº¦åˆ†æç»“æœä¿å­˜
                    for dim in sentiment_dict['dimensions'].keys():
                        df[f'{dim}ç»´åº¦å¾—åˆ†'] = [d.get(dim, 5.0) for d in dim_analysis_list]
                    
                    st.session_state.df = df
                    st.session_state.analyzed = True
                    st.session_state.dim_analysis = dim_analysis_list
                    progress_bar.empty()
                
                st.success("âœ… æƒ…æ„Ÿåˆ†æå®Œæˆï¼")
                
                # æ ¸å¿ƒç»Ÿè®¡ç»“æœ
                st.subheader("ğŸ“Š æ ¸å¿ƒåˆ†æç»“æœ")
                col1, col2, col3, col4, col5 = st.columns(5)
                avg_score = np.mean(scores)
                col1.metric("å¹³å‡æƒ…æ„Ÿå¾—åˆ†", f"{avg_score:.2f}/10")
                col2.metric("éå¸¸ç§¯æå æ¯”", f"{sum(1 for l in labels if l == 'éå¸¸ç§¯æ')/len(labels)*100:.1f}%")
                col3.metric("ç§¯æå æ¯”", f"{sum(1 for l in labels if l == 'ç§¯æ')/len(labels)*100:.1f}%")
                col4.metric("ä¸­æ€§å æ¯”", f"{sum(1 for l in labels if l == 'ä¸­æ€§')/len(labels)*100:.1f}%")
                col5.metric("æ¶ˆæå æ¯”", f"{sum(1 for l in labels if l == 'æ¶ˆæ')/len(labels)*100:.1f}%")
                
                # ç»´åº¦å¹³å‡å¾—åˆ†
                st.subheader("ğŸ“ˆ å„ç»´åº¦å¹³å‡æƒ…æ„Ÿå¾—åˆ†")
                dim_avg_scores = {}
                for dim in sentiment_dict['dimensions'].keys():
                    dim_avg_scores[dim] = round(df[f'{dim}ç»´åº¦å¾—åˆ†'].mean(), 2)
                
                # ç»´åº¦å¾—åˆ†å¯è§†åŒ–
                dim_cols = st.columns(len(dim_avg_scores))
                for idx, (dim, score) in enumerate(dim_avg_scores.items()):
                    with dim_cols[idx]:
                        st.metric(f"{dim}ç»´åº¦", score)
                        # è¿›åº¦æ¡å±•ç¤º
                        st.progress(score/10)
                
                # ç»“æœé¢„è§ˆ
                with st.expander("ğŸ“‹ æŸ¥çœ‹å‰20æ¡åˆ†æç»“æœï¼ˆå«ç»´åº¦å¾—åˆ†ï¼‰", expanded=True):
                    display_cols = [content_col, 'æƒ…æ„Ÿå¾—åˆ†', 'æƒ…æ„Ÿæ ‡ç­¾'] + [f'{dim}ç»´åº¦å¾—åˆ†' for dim in sentiment_dict['dimensions'].keys()]
                    st.dataframe(df[display_cols].head(20), use_container_width=True)
                
                # ç»“æœå¯¼å‡º
                @st.cache_data
                def convert_df_to_csv(df):
                    return df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                
                csv_data = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœï¼ˆCSVï¼‰",
                    data=csv_data,
                    file_name=f"ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        except Exception as e:
            st.error(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")
            st.info("ğŸ’¡ å¸¸è§é—®é¢˜ï¼š1. æ–‡ä»¶ç¼–ç é—®é¢˜ 2. åˆ—åç‰¹æ®Šå­—ç¬¦ 3. æ–‡ä»¶æŸå")
# ---------------------- é¡µé¢3ï¼šå¯è§†åŒ–ä¸­å¿ƒ ----------------------
elif page == "ğŸ“ˆ å¯è§†åŒ–ä¸­å¿ƒ":
    if not st.session_state.analyzed:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶åˆ†ææ•°æ®")
    else:
        df = st.session_state.df
        content_col = st.session_state.content_col
        
        viz_type = st.selectbox(
            "é€‰æ‹©å¯è§†åŒ–ç±»å‹", 
            ["æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾", "æƒ…æ„Ÿå¾—åˆ†ç›´æ–¹å›¾", "ç»´åº¦æƒ…æ„Ÿé›·è¾¾å›¾", 
             "è¯„è®ºé•¿åº¦åˆ†æ", "æƒ…æ„Ÿè¯äº‘å›¾", "ç»´åº¦å¾—åˆ†å¯¹æ¯”","æœˆåº¦æƒ…æ„Ÿèµ°åŠ¿"]
        )
        
        # 1. æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
        if viz_type == "æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾":
            st.subheader("æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ")
            counts = df['æƒ…æ„Ÿæ ‡ç­¾'].value_counts()
            colors = [LABEL_COLORS.get(k, '#3498db') for k in counts.index]
            
            fig, ax = plt.subplots(figsize=(8, 6))
            wedges, texts, autotexts = ax.pie(
                counts.values, 
                labels=counts.index, 
                autopct='%1.1f%%', 
                colors=colors, 
                startangle=90,
                textprops={'fontsize': 10}
            )
            # ç¾åŒ–ç™¾åˆ†æ¯”æ–‡å­—
            for autotext in autotexts:
                autotext.set_color('white')
                autotext.set_fontweight('bold')
            
            ax.set_title('ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ', fontsize=14, fontweight='bold')
            st.pyplot(fig)
        
        # 2. æƒ…æ„Ÿå¾—åˆ†ç›´æ–¹å›¾
        elif viz_type == "æƒ…æ„Ÿå¾—åˆ†ç›´æ–¹å›¾":
            st.subheader("æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ")
            fig, ax = plt.subplots(figsize=(10, 5))
            
            # ç»˜åˆ¶ç›´æ–¹å›¾
            n, bins, patches = ax.hist(df['æƒ…æ„Ÿå¾—åˆ†'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
            
            # ä¸ºä¸åŒåŒºé—´ç€è‰²
            for i, patch in enumerate(patches):
                if bins[i] >= 9.0:
                    patch.set_facecolor('#2ecc71')  # éå¸¸ç§¯æ
                elif bins[i] >= 7.5:
                    patch.set_facecolor('#27ae60')  # ç§¯æ
                elif bins[i] >= 6.0:
                    patch.set_facecolor('#f1c40f')  # ç•¥å¾®ç§¯æ
                elif bins[i] >= 4.5:
                    patch.set_facecolor('#95a5a6')  # ä¸­æ€§
                else:
                    patch.set_facecolor('#e67e22')  # æ¶ˆæ
            
            # æ·»åŠ å‡å€¼çº¿
            mean_score = df['æƒ…æ„Ÿå¾—åˆ†'].mean()
            ax.axvline(mean_score, color='red', linestyle='--', linewidth=2, label=f'å‡å€¼: {mean_score:.2f}')
            
            ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ†ï¼ˆ1-10åˆ†ï¼‰', fontsize=12)
            ax.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12)
            ax.set_title('æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒç›´æ–¹å›¾', fontsize=14, fontweight='bold')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            st.pyplot(fig)
        
        # 3. ç»´åº¦æƒ…æ„Ÿé›·è¾¾å›¾
        elif viz_type == "ç»´åº¦æƒ…æ„Ÿé›·è¾¾å›¾":
            st.subheader("å„ç»´åº¦å¹³å‡æƒ…æ„Ÿå¾—åˆ†é›·è¾¾å›¾")
            
            # è®¡ç®—ç»´åº¦å¹³å‡å¾—åˆ†
            dim_scores = []
            dim_labels = []
            for dim in sentiment_dict['dimensions'].keys():
                dim_score = df[f'{dim}ç»´åº¦å¾—åˆ†'].mean()
                dim_scores.append(dim_score)
                dim_labels.append(dim)
            
            # ç»˜åˆ¶é›·è¾¾å›¾
            fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))
            
            # è§’åº¦è®¡ç®—
            angles = np.linspace(0, 2 * np.pi, len(dim_labels), endpoint=False).tolist()
            dim_scores += dim_scores[:1]  # é—­åˆå›¾å½¢
            angles += angles[:1]
            dim_labels += dim_labels[:1]
            
            # ç»˜åˆ¶
            ax.plot(angles, dim_scores, 'o-', linewidth=2, color='#3498db')
            ax.fill(angles, dim_scores, alpha=0.25, color='#3498db')
            
            # è®¾ç½®æ ‡ç­¾
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(dim_labels[:-1], fontsize=10)
            ax.set_ylim(0, 10)
            ax.set_yticks(np.arange(2, 11, 2))
            ax.set_title('ç”µå•†è¯„è®ºå„ç»´åº¦æƒ…æ„Ÿå¾—åˆ†', fontsize=14, fontweight='bold', pad=20)
            ax.grid(True)
            
            st.pyplot(fig)
        
        # 4. è¯„è®ºé•¿åº¦åˆ†æ
        elif viz_type == "è¯„è®ºé•¿åº¦åˆ†æ":
            st.subheader("è¯„è®ºé•¿åº¦ä¸æƒ…æ„Ÿå¾—åˆ†å…³ç³»")
            
            # è®¡ç®—è¯„è®ºé•¿åº¦
            df['è¯„è®ºé•¿åº¦'] = df[content_col].astype(str).apply(len)
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
            
            # ç®±çº¿å›¾ï¼šä¸åŒæƒ…æ„Ÿæ ‡ç­¾çš„è¯„è®ºé•¿åº¦
            df.boxplot(column='è¯„è®ºé•¿åº¦', by='æƒ…æ„Ÿæ ‡ç­¾', ax=ax1, patch_artist=True)
            ax1.set_title('å„æƒ…æ„Ÿæ ‡ç­¾è¯„è®ºé•¿åº¦åˆ†å¸ƒ', fontsize=12)
            ax1.set_xlabel('æƒ…æ„Ÿæ ‡ç­¾', fontsize=10)
            ax1.set_ylabel('è¯„è®ºé•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰', fontsize=10)
            ax1.grid(True, alpha=0.3)
            
            # æ•£ç‚¹å›¾ï¼šè¯„è®ºé•¿åº¦ vs æƒ…æ„Ÿå¾—åˆ†
            scatter = ax2.scatter(
                df['è¯„è®ºé•¿åº¦'], 
                df['æƒ…æ„Ÿå¾—åˆ†'], 
                alpha=0.5, 
                c=[LABEL_COLORS.get(label, '#3498db') for label in df['æƒ…æ„Ÿæ ‡ç­¾']]
            )
            ax2.set_xlabel('è¯„è®ºé•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰', fontsize=10)
            ax2.set_ylabel('æƒ…æ„Ÿå¾—åˆ†', fontsize=10)
            ax2.set_title('è¯„è®ºé•¿åº¦ vs æƒ…æ„Ÿå¾—åˆ†', fontsize=12)
            ax2.grid(True, alpha=0.3)
            ax2.axhline(y=7, color='green', linestyle='--', alpha=0.5, label='ç§¯æé˜ˆå€¼')
            ax2.axhline(y=4.5, color='red', linestyle='--', alpha=0.5, label='æ¶ˆæé˜ˆå€¼')
            ax2.legend()
            
            st.pyplot(fig)
            
            # ç›¸å…³æ€§åˆ†æ
            corr = df['è¯„è®ºé•¿åº¦'].corr(df['æƒ…æ„Ÿå¾—åˆ†'])
            st.info(f"ğŸ“Š è¯„è®ºé•¿åº¦ä¸æƒ…æ„Ÿå¾—åˆ†çš„ç›¸å…³ç³»æ•°ï¼š**{corr:.3f}**")
            if corr > 0.1:
                st.success("âœ… è¯„è®ºè¶Šé•¿ï¼Œæƒ…æ„Ÿè¶Šç§¯æï¼ˆå¼±æ­£ç›¸å…³ï¼‰")
            elif corr < -0.1:
                st.warning("âš ï¸ è¯„è®ºè¶Šé•¿ï¼Œæƒ…æ„Ÿè¶Šæ¶ˆæï¼ˆå¼±è´Ÿç›¸å…³ï¼‰")
            else:
                st.info("â„¹ï¸ è¯„è®ºé•¿åº¦ä¸æƒ…æ„Ÿå¾—åˆ†æ— æ˜æ˜¾ç›¸å…³æ€§")
        
        # 5. æƒ…æ„Ÿè¯äº‘å›¾
        elif viz_type == "æƒ…æ„Ÿè¯äº‘å›¾":  
            if not FONT_PATH:
                st.error("âŒ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“")
            else:
                text = df[content_col].astype(str).str.cat(sep=' ')
                # å®‰å…¨æ¸…ç†
                text = re.sub(r'[^\u4e00-\u9fa5]', ' ', text)                
                stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 
                             'ä¸€', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€',
                             'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™', 'é‚£', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬',
                             'è¿™ä¸ª', 'ä¸€ä¸ª', 'å¯ä»¥', 'å°±æ˜¯', 'éå¸¸', 'å·²ç»', 'ç°åœ¨', 'è§‰å¾—',
                             'è¿˜æ˜¯', 'å› ä¸º', 'æ‰€ä»¥', 'å¦‚æœ', 'è¿˜', 'æŠŠ', 'è¢«', 'è®©', 'ç»™'}                
                words = [w for w in jieba.lcut(text) if len(w) > 1 and w not in stop_words]                
                if words:
                    wc = WordCloud(
                        width=1000, height=600,
                        background_color='white',
                        font_path=FONT_PATH,
                        max_words=150,
                        collocations=False
                    ).generate(' '.join(words))
                    fig, ax = plt.subplots(figsize=(12, 6))
                    ax.imshow(wc, interpolation='bilinear')
                    ax.axis('off')
                    ax.set_title('è¯„è®ºè¯äº‘å›¾', fontsize=16, fontweight='bold')
                    st.pyplot(fig)
                else:
                    st.warning("âš ï¸ è¯é¢‘ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘")
        # 6. ç»´åº¦å¾—åˆ†å¯¹æ¯”
        elif viz_type == "ç»´åº¦å¾—åˆ†å¯¹æ¯”":
            st.subheader("å„ç»´åº¦æƒ…æ„Ÿå¾—åˆ†å¯¹æ¯”")
            
            # è®¡ç®—ç»´åº¦å¾—åˆ†
            dim_scores = []
            dim_labels = []
            for dim in sentiment_dict['dimensions'].keys():
                dim_scores.append(df[f'{dim}ç»´åº¦å¾—åˆ†'].mean())
                dim_labels.append(dim)
            
            # ç»˜åˆ¶æŸ±çŠ¶å›¾
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.bar(dim_labels, dim_scores, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6', '#1abc9c', '#e67e22'])
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                        f'{height:.2f}', ha='center', va='bottom', fontsize=9)
            
            ax.set_xlabel('ç”µå•†ç»´åº¦', fontsize=12)
            ax.set_ylabel('å¹³å‡æƒ…æ„Ÿå¾—åˆ†ï¼ˆ1-10åˆ†ï¼‰', fontsize=12)
            ax.set_title('å„ç»´åº¦æƒ…æ„Ÿå¾—åˆ†å¯¹æ¯”', fontsize=14, fontweight='bold')
            ax.set_ylim(0, 10)
            ax.grid(True, alpha=0.3, axis='y')
            
            # æ—‹è½¬xè½´æ ‡ç­¾
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            
            st.pyplot(fig)
        # 7. æœˆåº¦æƒ…æ„Ÿèµ°åŠ¿ï¼ˆæœ€ç»ˆä¿®æ­£ç‰ˆï¼‰
        # 7. æœˆåº¦æƒ…æ„Ÿèµ°åŠ¿ï¼ˆæœ€ç»ˆæ— é”™è¯¯ç‰ˆï¼‰
        elif viz_type == "æœˆåº¦æƒ…æ„Ÿèµ°åŠ¿":
            st.subheader("æœˆåº¦å¹³å‡æƒ…æ„Ÿå¾—åˆ†èµ°åŠ¿")
            
            # 1. æ£€æŸ¥å¿…è¦åˆ—
            required_cols = ['å•†å“å±æ€§', 'æƒ…æ„Ÿå¾—åˆ†']
            if not all(col in df.columns for col in required_cols):
                st.warning("âš ï¸ æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼ˆéœ€åŒ…å«'å•†å“å±æ€§'å’Œ'æƒ…æ„Ÿå¾—åˆ†'ï¼‰")
                st.info("ğŸ’¡ è¯·ç¡®ä¿ä¸Šä¼ çš„æ•°æ®åŒ…å«'å•†å“å±æ€§'åˆ—ï¼ˆæ ¼å¼ç¤ºä¾‹ï¼š@2025å¹´11æœˆ2æ—¥å·²è´­:1åŒ…*100æŠ½ï¼‰")
                st.stop()
            
            # 2. æ—¥æœŸæå–ï¼ˆé€‚é…@+æ—¥æœŸ+é¢å¤–å±æ€§ï¼‰
            def extract_date(text):
                if pd.isna(text):
                    return None
                text_str = str(text).strip()
                # ä»…æå–@åçš„æ—¥æœŸï¼Œå¿½ç•¥åç»­å±æ€§
                match = re.search(r'@(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)', text_str)
                if match:
                    try:
                        return pd.to_datetime(match.group(1), format='%Yå¹´%mæœˆ%dæ—¥')
                    except Exception as e:
                        st.warning(f"âš ï¸ æ—¥æœŸè§£æå¤±è´¥ï¼š{match.group(1)}ï¼ˆé”™è¯¯ï¼š{str(e)[:50]}ï¼‰")
                        return None
                return None
            
            # 3. æ•°æ®å¤„ç†+æ—¥å¿—
            df_temp = df.copy()
            df_temp['è¯„è®ºæ—¶é—´'] = df_temp['å•†å“å±æ€§'].apply(extract_date)
            valid_count = df_temp['è¯„è®ºæ—¶é—´'].notna().sum()
            df_temp = df_temp.dropna(subset=['è¯„è®ºæ—¶é—´'])
            
            # æ˜¾ç¤ºæå–ç»“æœï¼Œå¸®åŠ©æ’æŸ¥é—®é¢˜
            st.info(f"ğŸ“Š æ—¥æœŸæå–ç»“æœï¼š")
            st.info(f"- æ€»è¯„è®ºæ•°ï¼š{len(df)} æ¡")
            st.info(f"- æˆåŠŸæå–æ—¥æœŸï¼š{valid_count} æ¡ï¼ˆ{valid_count/len(df)*100:.1f}%ï¼‰")
            
            # æ— æœ‰æ•ˆæ•°æ®æ—¶ç»ˆæ­¢
            if len(df_temp) == 0:
                st.error("âŒ æ— æœ‰æ•ˆæ—¥æœŸæ•°æ®ï¼Œæ— æ³•ç”Ÿæˆæœˆåº¦èµ°åŠ¿")
                st.stop()
            
            # 4. æœˆåº¦åˆ†ç»„+è¡¥å…¨ç¼ºå¤±æœˆä»½ï¼ˆç¡®ä¿xè½´å®Œæ•´ï¼‰
            df_temp['æœˆä»½_dt'] = pd.to_datetime(df_temp['è¯„è®ºæ—¶é—´']).dt.to_period('M')
            # è®¡ç®—æœˆåº¦å¹³å‡å¾—åˆ†ï¼ˆå½’ä¸€åŒ–åˆ°0-1ï¼Œä¸è®ºæ–‡ä¸€è‡´ï¼‰
            sent_month = df_temp.groupby('æœˆä»½_dt')['æƒ…æ„Ÿå¾—åˆ†'].mean() / 10
            # è¡¥å…¨ç¼ºå¤±æœˆä»½ï¼ˆå¦‚7æœˆæ— æ•°æ®ï¼Œå¡«å……ä¸ºNaNï¼Œé¿å…xè½´æ–­å±‚ï¼‰
            if len(sent_month) >= 1:
                all_months = pd.period_range(start=sent_month.index.min(), end=sent_month.index.max(), freq='M')
                sent_month = sent_month.reindex(all_months, fill_value=np.nan)
            # è½¬ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œé¿å…Streamlitæ˜¾ç¤ºå¼‚å¸¸
            sent_month.index = sent_month.index.astype(str)
            
            # 5. æ•°æ®é‡éªŒè¯ï¼ˆè‡³å°‘2ä¸ªæœˆä»½æ‰ç”ŸæˆæŠ˜çº¿ï¼‰
            valid_month_count = sent_month.dropna().shape[0]
            if valid_month_count < 2:
                st.warning(f"âš ï¸ ä»…{valid_month_count}ä¸ªæœˆä»½æœ‰æœ‰æ•ˆæ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŠ˜çº¿èµ°åŠ¿")
                # æ˜¾ç¤ºè¡¨æ ¼æ›¿ä»£æŠ˜çº¿å›¾
                st.dataframe(
                    pd.DataFrame({
                        'æœˆä»½': sent_month.index,
                        'å½’ä¸€åŒ–æƒ…æ„Ÿå¾—åˆ†': sent_month.values.round(3)
                    }),
                    use_container_width=True
                )
                st.stop()
            
            # 6. ç»˜åˆ¶æŠ˜çº¿å›¾ï¼ˆç§»é™¤connectstyleï¼Œå…¼å®¹æ‰€æœ‰matplotlibç‰ˆæœ¬ï¼‰
            plt.clf()  # æ¸…é™¤ç¼“å­˜ï¼Œé¿å…æ®‹ç•™å›¾è¡¨å¹²æ‰°
            fig, ax = plt.subplots(figsize=(10, 5))
            # æ ¸å¿ƒç»˜å›¾ä»£ç ï¼ˆä¿ç•™è®ºæ–‡åŒæ¬¾æ ·å¼ï¼‰
            sent_month.plot(
                marker='o',        # åœ†å½¢æ ‡è®°ç‚¹ï¼ˆä¸è®ºæ–‡å›¾2ä¸€è‡´ï¼‰
                color='teal',       # çº¿æ¡é¢œè‰²ï¼ˆä¸è®ºæ–‡ä¸€è‡´ï¼‰
                linewidth=2,        # çº¿æ¡ç²—ç»†
                markersize=6,       # æ ‡è®°ç‚¹å¤§å°
                ax=ax              # æŒ‡å®šåæ ‡è½´
            )
            
            # æ ·å¼ä¼˜åŒ–ï¼ˆè´´åˆè®ºæ–‡ï¼‰
            ax.set_title('å¿ƒç›¸å°è¯„è®ºæœˆåº¦å¹³å‡æƒ…æ„Ÿå¾—åˆ†èµ°åŠ¿', fontsize=14, fontweight='bold')
            ax.set_ylabel('æƒ…æ„Ÿå¾—åˆ†ï¼ˆå½’ä¸€åŒ–ï¼‰', fontsize=12)
            ax.set_xlabel('æœˆä»½', fontsize=12)
            ax.grid(True, linestyle='--', alpha=0.5)  # è™šçº¿ç½‘æ ¼ï¼ˆä¸è®ºæ–‡ä¸€è‡´ï¼‰
            # è‡ªé€‚åº”yè½´èŒƒå›´ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®å¯è§ï¼ˆè§£å†³ä¹‹å‰â€œæ•°æ®è—åœ¨è½´å¤–â€çš„é—®é¢˜ï¼‰
            ax.set_ylim(
                bottom=sent_month.dropna().min() - 0.05,
                top=sent_month.dropna().max() + 0.05
            )
            # æ—‹è½¬xè½´æ ‡ç­¾ï¼Œé¿å…é‡å 
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()  # è‡ªåŠ¨è°ƒæ•´å¸ƒå±€ï¼Œé˜²æ­¢æ ‡ç­¾è¢«æˆªæ–­
            
            # 7. æ˜¾ç¤ºå›¾è¡¨ï¼ˆStreamlitä¸“ç”¨å‡½æ•°ï¼Œä¸å¯é—æ¼ï¼‰
            st.pyplot(fig)
            st.success("âœ… æœˆåº¦æƒ…æ„Ÿèµ°åŠ¿å›¾è¡¨ç”ŸæˆæˆåŠŸï¼")
            
            # 8. è¡¥å……è®ºæ–‡å…³é”®ç»“è®º
            st.info(f"ğŸ” å…³é”®ç»“è®ºï¼š")
            st.info(f"- æƒ…æ„Ÿæœ€é«˜æœˆä»½ï¼š{sent_month.idxmax()}ï¼ˆå¾—åˆ†ï¼š{sent_month.max():.3f}ï¼‰")
            st.info(f"- æƒ…æ„Ÿæœ€ä½æœˆä»½ï¼š{sent_month.idxmin()}ï¼ˆå¾—åˆ†ï¼š{sent_month.min():.3f}ï¼‰")
            st.info(f"- æ•´ä½“å¹³å‡å¾—åˆ†ï¼š{sent_month.mean():.3f}")

# ---------------------- é¡µé¢4ï¼šå•æ¡é¢„æµ‹ ----------------------
elif page == "ğŸ¤– å•æ¡é¢„æµ‹":
    st.header("å®æ—¶æƒ…æ„Ÿé¢„æµ‹ï¼ˆå•æ¡è¯„è®ºï¼‰")
    
    # å•†å“ç±»åˆ«é€‰æ‹©
    category = st.selectbox("å•†å“ç±»åˆ«", ["é€šç”¨", "æ•°ç ", "æœè£…", "é£Ÿå“", "ç¾å¦†", "å®¶å±…", "å®¶ç”µ"])
    
    # è¯„è®ºè¾“å…¥
    text = st.text_area(
        "è¾“å…¥è¯„è®ºå†…å®¹", 
        height=120, 
        placeholder="ä¾‹å¦‚ï¼šè¿™æ¬¾äº§å“è´¨é‡è¶…å¥½ï¼Œç‰©æµä¹Ÿå¾ˆå¿«ï¼Œæ€§ä»·æ¯”æé«˜ï¼",
        help="æ”¯æŒå…¨å“ç±»ç”µå•†è¯„è®ºï¼Œä¼šè‡ªåŠ¨è¯†åˆ«æƒ…æ„Ÿè¯å’Œç»´åº¦è¯"
    )
    
    if st.button("ğŸš€ åˆ†ææƒ…æ„Ÿ", type="primary"):
        if text:
            # è®¡ç®—æƒ…æ„Ÿå¾—åˆ†å’Œç»´åº¦åˆ†æ
            score, dim_analysis = calculate_sentiment_score(text, sentiment_dict)
            label = get_sentiment_label(score)
            
            # æ ¸å¿ƒç»“æœå±•ç¤º
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("æƒ…æ„Ÿå¾—åˆ†", f"{score}/10")
            col2.metric("æƒ…æ„Ÿæ ‡ç­¾", label)
            
            # è¡¨æƒ…æ˜ å°„
            emoji_map = {
                "éå¸¸ç§¯æ": "ğŸ˜„", "ç§¯æ": "ğŸ™‚", "ç•¥å¾®ç§¯æ": "ğŸ˜Š",
                "ä¸­æ€§": "ğŸ˜", "æ¶ˆæ": "ğŸ˜•"
            }
            col3.metric("æƒ…æ„Ÿè¡¨æƒ…", emoji_map.get(label, "â“"))
            
            # æƒ…æ„Ÿå¼ºåº¦
            intensity = "æå¼º" if score >= 9 else "å¼º" if score >= 7.5 else "å¼±" if score >= 6 else "ä¸­æ€§" if score >= 4.5 else "å¼±" if score >= 3 else "å¼º"
            col4.metric("æƒ…æ„Ÿå¼ºåº¦", intensity)
            
            # è¿›åº¦æ¡å±•ç¤º
            st.progress(score/10)
            
            # æƒ…æ„Ÿç»“è®º
            if score >= 9.0:
                st.success(f"ğŸ‘ éå¸¸ç§¯æè¯„ä»·ï¼ç”¨æˆ·æ»¡æ„åº¦æé«˜ï¼Œå±äºæ ¸å¿ƒå¥½è¯„ã€‚")
            elif score >= 7.5:
                st.success(f"ğŸ‘ ç§¯æè¯„ä»·ï¼ç”¨æˆ·æ»¡æ„åº¦é«˜ï¼Œå¯ä½œä¸ºæ¨èç†ç”±ã€‚")
            elif score >= 6.0:
                st.info(f"ğŸ˜Š ç•¥å¾®ç§¯æè¯„ä»·ï¼ç”¨æˆ·åŸºæœ¬æ»¡æ„ï¼Œæœ‰å°å¹…æå‡ç©ºé—´ã€‚")
            elif score >= 4.5:
                st.info(f"ğŸ˜ ä¸­æ€§è¯„ä»·ï¼ç”¨æˆ·æ— æ˜æ˜¾æƒ…æ„Ÿå€¾å‘ï¼Œéœ€è¿›ä¸€æ­¥æŒ–æ˜éœ€æ±‚ã€‚")
            else:
                st.error(f"ğŸ‘ æ¶ˆæè¯„ä»·ï¼ç”¨æˆ·æ»¡æ„åº¦ä½ï¼Œå»ºè®®å®¢æœä»‹å…¥å¤„ç†ã€‚")
            
            # ç»´åº¦åˆ†æç»“æœ
            if dim_analysis:
                st.subheader("ğŸ“ˆ ç»´åº¦æƒ…æ„Ÿåˆ†æ")
                dim_cols = st.columns(len(dim_analysis))
                for idx, (dim, dim_score) in enumerate(dim_analysis.items()):
                    with dim_cols[idx]:
                        st.metric(f"{dim}ç»´åº¦", dim_score)
                        st.progress(dim_score/10)
            
            # è¯¦ç»†åˆ†æ
            with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†åˆ†æ", expanded=True):
                # åˆ†è¯ç»“æœ
                words = jieba.lcut(text)
                st.write(f"åˆ†è¯ç»“æœï¼š{', '.join(words)}")
                
                # æƒ…æ„Ÿè¯è¯†åˆ«
                sentiment_words_found = []
                for sentiment_type, word_dict in sentiment_dict['sentiment'].items():
                    for word, s_score in word_dict.items():
                        if word in text:
                            sentiment_words_found.append(f"{word}ï¼ˆå¾—åˆ†ï¼š{s_score}ï¼‰")
                
                if sentiment_words_found:
                    st.write(f"è¯†åˆ«åˆ°çš„æƒ…æ„Ÿè¯ï¼š{', '.join(sentiment_words_found)}")
                else:
                    st.write("æœªè¯†åˆ«åˆ°æ˜æ˜¾æƒ…æ„Ÿè¯ï¼Œæƒ…æ„Ÿå¾—åˆ†ä¸ºä¸­æ€§åŸºå‡†åˆ†ã€‚")
                
                # å¦å®šè¯/ç¨‹åº¦å‰¯è¯è¯†åˆ«
                neg_words_found = [w for w in sentiment_dict['negations'].keys() if w in text]
                degree_words_found = [w for w in sentiment_dict['degrees'].keys() if w in text]
                
                if neg_words_found:
                    st.write(f"è¯†åˆ«åˆ°çš„å¦å®šè¯ï¼š{', '.join(neg_words_found)}ï¼ˆå·²åè½¬æƒ…æ„Ÿå¾—åˆ†ï¼‰")
                if degree_words_found:
                    st.write(f"è¯†åˆ«åˆ°çš„ç¨‹åº¦å‰¯è¯ï¼š{', '.join(degree_words_found)}ï¼ˆå·²è°ƒæ•´æƒ…æ„Ÿå¼ºåº¦ï¼‰")
        else:
            st.warning("âš ï¸ è¯·è¾“å…¥è¯„è®ºå†…å®¹åå†è¿›è¡Œåˆ†æï¼")

# ---------------------- é¡µé¢5ï¼šè¯å…¸ç®¡ç† ----------------------
elif page == "ğŸ“‹ è¯å…¸ç®¡ç†":
    st.header("ç”µå•†æƒ…æ„Ÿè¯å…¸ç®¡ç†")
    
    # è¯å…¸ç±»å‹é€‰æ‹©
    dict_type = st.selectbox(
        "é€‰æ‹©è¯å…¸ç±»å‹",
        ["æ ¸å¿ƒæƒ…æ„Ÿè¯", "ç”µå•†ç»´åº¦è¯", "å¦å®šè¯", "ç¨‹åº¦å‰¯è¯", "æ˜ç¡®æ¨¡å¼"]
    )
    
    # å±•ç¤ºå¯¹åº”è¯å…¸å†…å®¹
    if dict_type == "æ ¸å¿ƒæƒ…æ„Ÿè¯":
        st.subheader("æ ¸å¿ƒæƒ…æ„Ÿè¯ï¼ˆå¸¦å¼ºåº¦è¯„åˆ†ï¼‰")
        # æŒ‰ç±»å‹å±•ç¤º
        for sentiment_type, word_dict in sentiment_dict['sentiment'].items():
            with st.expander(f"{sentiment_type.replace('_', ' ')}", expanded=False):
                # è½¬æ¢ä¸ºDataFrameå±•ç¤º
                df_words = pd.DataFrame(list(word_dict.items()), columns=['è¯æ±‡', 'æƒ…æ„Ÿå¾—åˆ†'])
                st.dataframe(df_words, use_container_width=True)
    
    elif dict_type == "ç”µå•†ç»´åº¦è¯":
        st.subheader("ç”µå•†ç»´åº¦è¯ï¼ˆ7å¤§æ ¸å¿ƒç»´åº¦ï¼‰")
        for dim, words in sentiment_dict['dimensions'].items():
            st.write(f"**{dim}ç»´åº¦**ï¼š{', '.join(words)}")
    
    elif dict_type == "å¦å®šè¯":
        st.subheader("å¦å®šè¯ï¼ˆå¸¦åè½¬æƒé‡ï¼‰")
        df_neg = pd.DataFrame(list(sentiment_dict['negations'].items()), columns=['å¦å®šè¯', 'åè½¬æƒé‡'])
        st.dataframe(df_neg, use_container_width=True)
    
    elif dict_type == "ç¨‹åº¦å‰¯è¯":
        st.subheader("ç¨‹åº¦å‰¯è¯ï¼ˆå¸¦å¼ºåº¦æƒé‡ï¼‰")
        df_degree = pd.DataFrame(list(sentiment_dict['degrees'].items()), columns=['ç¨‹åº¦å‰¯è¯', 'å¼ºåº¦æƒé‡'])
        st.dataframe(df_degree, use_container_width=True)
    
    elif dict_type == "æ˜ç¡®æ¨¡å¼":
        st.subheader("æ˜ç¡®æ¨¡å¼ï¼ˆç›´æ¥å¾—åˆ†ï¼‰")
        df_explicit = pd.DataFrame(list(sentiment_dict['explicit'].items()), columns=['æ¨¡å¼çŸ­è¯­', 'ç›´æ¥å¾—åˆ†'])
        st.dataframe(df_explicit, use_container_width=True)
    
    # è¯å…¸å¯¼å‡ºåŠŸèƒ½
    st.subheader("ğŸ“¥ è¯å…¸å¯¼å‡º")
    if st.button("å¯¼å‡ºå®Œæ•´æƒ…æ„Ÿè¯å…¸ï¼ˆJSONï¼‰"):
        # è½¬æ¢ä¸ºJSONæ ¼å¼
        dict_json = json.dumps(sentiment_dict, ensure_ascii=False, indent=4)
        st.download_button(
            label="ä¸‹è½½JSONæ–‡ä»¶",
            data=dict_json,
            file_name=f"ç”µå•†æƒ…æ„Ÿè¯å…¸_{datetime.now().strftime('%Y%m%d')}.json",
            mime="application/json"
        )

# é¡µè„šä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.info("åŸºäºæ·±åº¦å­¦ä¹ çš„ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
st.sidebar.markdown("ğŸ“… æ›´æ–°æ—¶é—´ï¼š2026-02-01")
